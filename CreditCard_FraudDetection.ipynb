{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. IMPORTING DEPENDENCIES"
      ],
      "metadata": {
        "id": "9_8kuq8d5pza"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GHgwx1jx5aqH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, confusion_matrix, classification_report,\n",
        "                             roc_auc_score)\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. LOAD AND EXPLORE DATA"
      ],
      "metadata": {
        "id": "jsi95gOR6ELN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset\n",
        "credit_card_data = pd.read_csv('creditcard.csv')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nDataset Shape: {credit_card_data.shape}\")\n",
        "print(f\"Total Transactions: {len(credit_card_data)}\")\n",
        "\n",
        "#check for missing values\n",
        "print(f\"\\nMissing Values:\\n{credit_card_data.isnull().sum().sum()} total missing values\")\n",
        "\n",
        "#handle the last row with missing values (identified in original notebook)\n",
        "credit_card_data = credit_card_data.dropna()\n",
        "\n",
        "print(f\"\\nAfter removing missing values: {credit_card_data.shape}\")\n",
        "\n",
        "#class distribution\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLASS DISTRIBUTION\")\n",
        "print(\"=\"*70)\n",
        "class_dist = credit_card_data['Class'].value_counts()\n",
        "print(f\"\\nLegitimate Transactions (0): {class_dist[0]} ({class_dist[0]/len(credit_card_data)*100:.2f}%)\")\n",
        "print(f\"Fraudulent Transactions (1): {class_dist[1]} ({class_dist[1]/len(credit_card_data)*100:.2f}%)\")\n",
        "print(f\"\\nImbalance Ratio: {class_dist[0]/class_dist[1]:.2f}:1\")\n",
        "\n",
        "#statistical summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRANSACTION AMOUNT STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "legit = credit_card_data[credit_card_data.Class == 0]\n",
        "fraud = credit_card_data[credit_card_data.Class == 1]\n",
        "\n",
        "print(\"\\nLegitimate Transactions:\")\n",
        "print(legit['Amount'].describe())\n",
        "print(\"\\nFraudulent Transactions:\")\n",
        "print(fraud['Amount'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IJUfTmB6BP1",
        "outputId": "612981f0-1f4a-4985-f4b5-51e7ea553795"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DATASET OVERVIEW\n",
            "======================================================================\n",
            "\n",
            "Dataset Shape: (284807, 31)\n",
            "Total Transactions: 284807\n",
            "\n",
            "Missing Values:\n",
            "0 total missing values\n",
            "\n",
            "After removing missing values: (284807, 31)\n",
            "\n",
            "======================================================================\n",
            "CLASS DISTRIBUTION\n",
            "======================================================================\n",
            "\n",
            "Legitimate Transactions (0): 284315 (99.83%)\n",
            "Fraudulent Transactions (1): 492 (0.17%)\n",
            "\n",
            "Imbalance Ratio: 577.88:1\n",
            "\n",
            "======================================================================\n",
            "TRANSACTION AMOUNT STATISTICS\n",
            "======================================================================\n",
            "\n",
            "Legitimate Transactions:\n",
            "count    284315.000000\n",
            "mean         88.291022\n",
            "std         250.105092\n",
            "min           0.000000\n",
            "25%           5.650000\n",
            "50%          22.000000\n",
            "75%          77.050000\n",
            "max       25691.160000\n",
            "Name: Amount, dtype: float64\n",
            "\n",
            "Fraudulent Transactions:\n",
            "count     492.000000\n",
            "mean      122.211321\n",
            "std       256.683288\n",
            "min         0.000000\n",
            "25%         1.000000\n",
            "50%         9.250000\n",
            "75%       105.890000\n",
            "max      2125.870000\n",
            "Name: Amount, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. DATA PREPARATION"
      ],
      "metadata": {
        "id": "F4ctjOrF6YWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA PREPARATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Separate features and target\n",
        "X = credit_card_data.drop(columns='Class', axis=1)\n",
        "Y = credit_card_data['Class']\n",
        "\n",
        "# Split the data (80-20 split)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, stratify=Y, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining Set: {X_train.shape}\")\n",
        "print(f\"Testing Set: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLJw20aq6aSN",
        "outputId": "69e8dab3-ba8a-40a0-b4f8-cd52d8cee266"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATA PREPARATION\n",
            "======================================================================\n",
            "\n",
            "Training Set: (227845, 30)\n",
            "Testing Set: (56962, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. SAMPLING STRATEGIES"
      ],
      "metadata": {
        "id": "7fJrveF46cKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAMPLING STRATEGIES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Strategy 1: Random Undersampling (from original notebook)\n",
        "legit_train = X_train[Y_train == 0]\n",
        "fraud_train = X_train[Y_train == 1]\n",
        "legit_sample = legit_train.sample(n=len(fraud_train), random_state=42)\n",
        "\n",
        "X_train_under = pd.concat([legit_sample, fraud_train], axis=0)\n",
        "Y_train_under = pd.concat([\n",
        "    pd.Series([0]*len(legit_sample)),\n",
        "    pd.Series([1]*len(fraud_train))\n",
        "], axis=0)\n",
        "\n",
        "print(f\"\\n1. Random Undersampling:\")\n",
        "print(f\"   Training samples: {len(X_train_under)}\")\n",
        "print(f\"   Class distribution: {Y_train_under.value_counts().to_dict()}\")\n",
        "\n",
        "# Strategy 2: SMOTE (Oversampling)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, Y_train_smote = smote.fit_resample(X_train, Y_train)\n",
        "\n",
        "print(f\"\\n2. SMOTE Oversampling:\")\n",
        "print(f\"   Training samples: {len(X_train_smote)}\")\n",
        "print(f\"   Class distribution: {Y_train_smote.value_counts().to_dict()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkbkNYQw6eF-",
        "outputId": "494368b0-f68a-4f0b-d1a4-078c4051cfe9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SAMPLING STRATEGIES\n",
            "======================================================================\n",
            "\n",
            "1. Random Undersampling:\n",
            "   Training samples: 788\n",
            "   Class distribution: {0: 394, 1: 394}\n",
            "\n",
            "2. SMOTE Oversampling:\n",
            "   Training samples: 454902\n",
            "   Class distribution: {0: 227451, 1: 227451}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. MODEL TRAINING AND EVALUATION"
      ],
      "metadata": {
        "id": "Y3ovVISY6hg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, Y_train, X_test, Y_test, model_name):\n",
        "    \"\"\"Comprehensive model evaluation\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"EVALUATING: {model_name}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # Predictions\n",
        "    Y_train_pred = model.predict(X_train)\n",
        "    Y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        'Training Accuracy': accuracy_score(Y_train, Y_train_pred),\n",
        "        'Testing Accuracy': accuracy_score(Y_test, Y_test_pred),\n",
        "        'Precision': precision_score(Y_test, Y_test_pred),\n",
        "        'Recall': recall_score(Y_test, Y_test_pred),\n",
        "        'F1-Score': f1_score(Y_test, Y_test_pred),\n",
        "        'ROC-AUC': roc_auc_score(Y_test, Y_test_pred)\n",
        "    }\n",
        "\n",
        "    print(\"\\nPerformance Metrics:\")\n",
        "    print(\"-\" * 50)\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric:20s}: {value:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(Y_test, Y_test_pred)\n",
        "    print(cm)\n",
        "    print(f\"\\nTrue Negatives:  {cm[0][0]}\")\n",
        "    print(f\"False Positives: {cm[0][1]}\")\n",
        "    print(f\"False Negatives: {cm[1][0]}\")\n",
        "    print(f\"True Positives:  {cm[1][1]}\")\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(Y_test, Y_test_pred,\n",
        "                                target_names=['Legitimate', 'Fraud']))\n",
        "\n",
        "    return model, metrics"
      ],
      "metadata": {
        "id": "IAiBN4DJ6hQc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: Logistic Regression with Undersampling"
      ],
      "metadata": {
        "id": "CA82EX6W6mKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_under = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_under_model, lr_under_metrics = evaluate_model(\n",
        "    lr_under, X_train_under, Y_train_under, X_test, Y_test,\n",
        "    \"Logistic Regression (Undersampling)\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxR5TS6t6pAS",
        "outputId": "c2961395-9171-4f4b-9739-5718d0c69968"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATING: Logistic Regression (Undersampling)\n",
            "======================================================================\n",
            "\n",
            "Performance Metrics:\n",
            "--------------------------------------------------\n",
            "Training Accuracy   : 0.9569\n",
            "Testing Accuracy    : 0.9599\n",
            "Precision           : 0.0380\n",
            "Recall              : 0.9184\n",
            "F1-Score            : 0.0731\n",
            "ROC-AUC             : 0.9392\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54588  2276]\n",
            " [    8    90]]\n",
            "\n",
            "True Negatives:  54588\n",
            "False Positives: 2276\n",
            "False Negatives: 8\n",
            "True Positives:  90\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Legitimate       1.00      0.96      0.98     56864\n",
            "       Fraud       0.04      0.92      0.07        98\n",
            "\n",
            "    accuracy                           0.96     56962\n",
            "   macro avg       0.52      0.94      0.53     56962\n",
            "weighted avg       1.00      0.96      0.98     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: Logistic Regression with SMOTE"
      ],
      "metadata": {
        "id": "D5N_ieLw6pzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_smote = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_smote_model, lr_smote_metrics = evaluate_model(\n",
        "    lr_smote, X_train_smote, Y_train_smote, X_test, Y_test,\n",
        "    \"Logistic Regression (SMOTE)\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojrYLhLs6pjl",
        "outputId": "baa76f19-db38-4081-c415-27ef89a66f60"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATING: Logistic Regression (SMOTE)\n",
            "======================================================================\n",
            "\n",
            "Performance Metrics:\n",
            "--------------------------------------------------\n",
            "Training Accuracy   : 0.9787\n",
            "Testing Accuracy    : 0.9884\n",
            "Precision           : 0.1191\n",
            "Recall              : 0.8980\n",
            "F1-Score            : 0.2103\n",
            "ROC-AUC             : 0.9433\n",
            "\n",
            "Confusion Matrix:\n",
            "[[56213   651]\n",
            " [   10    88]]\n",
            "\n",
            "True Negatives:  56213\n",
            "False Positives: 651\n",
            "False Negatives: 10\n",
            "True Positives:  88\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Legitimate       1.00      0.99      0.99     56864\n",
            "       Fraud       0.12      0.90      0.21        98\n",
            "\n",
            "    accuracy                           0.99     56962\n",
            "   macro avg       0.56      0.94      0.60     56962\n",
            "weighted avg       1.00      0.99      0.99     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3: Random Forest with Undersampling\n"
      ],
      "metadata": {
        "id": "b1cJBEbg6tgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_under = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_under_model, rf_under_metrics = evaluate_model(\n",
        "    rf_under, X_train_under, Y_train_under, X_test, Y_test,\n",
        "    \"Random Forest (Undersampling)\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXS-Ae4n6v3d",
        "outputId": "25282238-8521-40bb-875e-a1a756274a44"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATING: Random Forest (Undersampling)\n",
            "======================================================================\n",
            "\n",
            "Performance Metrics:\n",
            "--------------------------------------------------\n",
            "Training Accuracy   : 1.0000\n",
            "Testing Accuracy    : 0.9641\n",
            "Precision           : 0.0423\n",
            "Recall              : 0.9184\n",
            "F1-Score            : 0.0809\n",
            "ROC-AUC             : 0.9413\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54827  2037]\n",
            " [    8    90]]\n",
            "\n",
            "True Negatives:  54827\n",
            "False Positives: 2037\n",
            "False Negatives: 8\n",
            "True Positives:  90\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Legitimate       1.00      0.96      0.98     56864\n",
            "       Fraud       0.04      0.92      0.08        98\n",
            "\n",
            "    accuracy                           0.96     56962\n",
            "   macro avg       0.52      0.94      0.53     56962\n",
            "weighted avg       1.00      0.96      0.98     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4: Random Forest with SMOTE\n"
      ],
      "metadata": {
        "id": "QxpAvjER6xn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_smote = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_smote_model, rf_smote_metrics = evaluate_model(\n",
        "    rf_smote, X_train_smote, Y_train_smote, X_test, Y_test,\n",
        "    \"Random Forest (SMOTE)\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAK5LrGJ6zFt",
        "outputId": "9ed5bd6a-0bb7-46b8-aee6-c7f59937355c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATING: Random Forest (SMOTE)\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. MODEL COMPARISON\n"
      ],
      "metadata": {
        "id": "OBgB4kbx66iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'LR (Under)': lr_under_metrics,\n",
        "    'LR (SMOTE)': lr_smote_metrics,\n",
        "    'RF (Under)': rf_under_metrics,\n",
        "    'RF (SMOTE)': rf_smote_metrics\n",
        "})\n",
        "\n",
        "print(\"\\n\", comparison_df.round(4))"
      ],
      "metadata": {
        "id": "_Z9wkXnt6xYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. FEATURE IMPORTANCE (for Random Forest)\n"
      ],
      "metadata": {
        "id": "sMKh1u_M687o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TOP 10 IMPORTANT FEATURES (Random Forest - SMOTE)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': rf_smote_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\n\", feature_importance.head(10).to_string(index=False))"
      ],
      "metadata": {
        "id": "niUAdmKl6-oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. RECOMMENDATIONS\n",
        "\n",
        "### 1. BEST MODEL SELECTION:\n",
        "   - For maximizing fraud detection (Recall): Random Forest with SMOTE\n",
        "   - For balanced performance: Random Forest with undersampling\n",
        "   - For production deployment: Consider ensemble of top models\n",
        "\n",
        "### 2. KEY INSIGHTS:\n",
        "   - Random Forest outperforms Logistic Regression\n",
        "   - SMOTE generally provides better recall for fraud detection\n",
        "   - High feature importance for V14, V17, V12, V10\n",
        "\n",
        "### 3. NEXT STEPS:\n",
        "   - Implement hyperparameter tuning (GridSearchCV/RandomizedSearchCV)\n",
        "   - Try XGBoost or LightGBM for potentially better performance\n",
        "   - Implement cost-sensitive learning\n",
        "   - Deploy with real-time monitoring\n",
        "   - Set up alert system for predicted fraudulent transactions\n",
        "\n",
        "### 4. PRODUCTION CONSIDERATIONS:\n",
        "   - Monitor for data drift\n",
        "   - Regular model retraining\n",
        "   - A/B testing for model updates\n",
        "   - Consider threshold adjustment based on business cost"
      ],
      "metadata": {
        "id": "fHQH645W7Avw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6HB3y6cK7FBr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}