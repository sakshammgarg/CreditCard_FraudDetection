{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "sbdD6h8dymFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "H076MW24ymVU"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Explore Dataset"
      ],
      "metadata": {
        "id": "P_nA8bZlyuNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2EShWy7EywJc",
        "outputId": "8d838baf-de64-498e-8029-ad7afafce034"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (284807, 31)\n",
            "\n",
            "First few rows:\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze Class Imbalance"
      ],
      "metadata": {
        "id": "N8gDycZeyyyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Class Distribution:\")\n",
        "print(df['Class'].value_counts())\n",
        "print(\"\\nClass Distribution (%):\")\n",
        "print(df['Class'].value_counts(normalize=True) * 100)\n",
        "\n",
        "print(\"\\nTransaction Amount Statistics:\")\n",
        "print(df['Amount'].describe())\n",
        "\n",
        "print(\"\\nFraud vs Legitimate Amount Statistics:\")\n",
        "print(\"\\nFraudulent Transactions:\")\n",
        "print(df[df['Class'] == 1]['Amount'].describe())\n",
        "print(\"\\nLegitimate Transactions:\")\n",
        "print(df[df['Class'] == 0]['Amount'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C2-Hp3gXyzH6",
        "outputId": "f9210865-6758-43f8-90a6-320f7187bd4c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "Class\n",
            "0    284315\n",
            "1       492\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class Distribution (%):\n",
            "Class\n",
            "0    99.827251\n",
            "1     0.172749\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Transaction Amount Statistics:\n",
            "count    284807.000000\n",
            "mean         88.349619\n",
            "std         250.120109\n",
            "min           0.000000\n",
            "25%           5.600000\n",
            "50%          22.000000\n",
            "75%          77.165000\n",
            "max       25691.160000\n",
            "Name: Amount, dtype: float64\n",
            "\n",
            "Fraud vs Legitimate Amount Statistics:\n",
            "\n",
            "Fraudulent Transactions:\n",
            "count     492.000000\n",
            "mean      122.211321\n",
            "std       256.683288\n",
            "min         0.000000\n",
            "25%         1.000000\n",
            "50%         9.250000\n",
            "75%       105.890000\n",
            "max      2125.870000\n",
            "Name: Amount, dtype: float64\n",
            "\n",
            "Legitimate Transactions:\n",
            "count    284315.000000\n",
            "mean         88.291022\n",
            "std         250.105092\n",
            "min           0.000000\n",
            "25%           5.650000\n",
            "50%          22.000000\n",
            "75%          77.050000\n",
            "max       25691.160000\n",
            "Name: Amount, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "nRyIah1Iy3Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any incomplete records\n",
        "df_clean = df.dropna()\n",
        "print(f\"Records after removing incomplete data: {len(df_clean)}\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df_clean.drop('Class', axis=1)\n",
        "Y = df_clean['Class']\n",
        "\n",
        "print(f\"\\nFeatures shape: {X.shape}\")\n",
        "print(f\"Target shape: {Y.shape}\")\n",
        "print(f\"\\nFeature columns: {list(X.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFqW0ZNqy2l-",
        "outputId": "c9d79e5c-2ca9-4dab-93fb-a63e8092e696"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Records after removing incomplete data: 284807\n",
            "\n",
            "Features shape: (284807, 30)\n",
            "Target shape: (284807,)\n",
            "\n",
            "Feature columns: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Validation/Test Split"
      ],
      "metadata": {
        "id": "Lku90rriy5Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First split: 70% train, 30% temp (for validation + test)\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
        "    X, Y, test_size=0.30, random_state=42, stratify=Y\n",
        ")\n",
        "\n",
        "# Second split: Split temp into 50% validation, 50% test (15% each of total)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(\n",
        "    X_temp, Y_temp, test_size=0.50, random_state=42, stratify=Y_temp\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Validation set size: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
        "print(f\"Test set size: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nTraining set - Fraud cases: {Y_train.sum()}, Legitimate cases: {(Y_train==0).sum()}\")\n",
        "print(f\"Validation set - Fraud cases: {Y_val.sum()}, Legitimate cases: {(Y_val==0).sum()}\")\n",
        "print(f\"Test set - Fraud cases: {Y_test.sum()}, Legitimate cases: {(Y_test==0).sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFalL9Dxy5V0",
        "outputId": "a34bf887-1007-41c0-e37a-bb969cd5ce09"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 199364 (70.0%)\n",
            "Validation set size: 42721 (15.0%)\n",
            "Test set size: 42722 (15.0%)\n",
            "\n",
            "Training set - Fraud cases: 344, Legitimate cases: 199020\n",
            "Validation set - Fraud cases: 74, Legitimate cases: 42647\n",
            "Test set - Fraud cases: 74, Legitimate cases: 42648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "Sw8YnyoKy5hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_threshold(Y_true, Y_pred_proba, thresholds=np.arange(0.1, 0.9, 0.01)):\n",
        "    best_threshold = 0.5\n",
        "    best_f1 = 0\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        Y_pred = (Y_pred_proba >= threshold).astype(int)\n",
        "        f1 = f1_score(Y_true, Y_pred)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "\n",
        "    return best_threshold, best_f1\n",
        "\n",
        "def evaluate_model(model, X_test, Y_test, threshold=0.5, model_name=\"Model\"):\n",
        "    Y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    Y_pred = (Y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(Y_test, Y_pred)\n",
        "    prec = precision_score(Y_test, Y_pred, zero_division=0)\n",
        "    rec = recall_score(Y_test, Y_pred)\n",
        "    f1 = f1_score(Y_test, Y_pred)\n",
        "    roc_auc = roc_auc_score(Y_test, Y_pred_proba)\n",
        "    cm = confusion_matrix(Y_test, Y_pred)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Threshold: {threshold:.3f}\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall: {rec:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"TN: {cm[0][0]}, FP: {cm[0][1]}\")\n",
        "    print(f\"FN: {cm[1][0]}, TP: {cm[1][1]}\")\n",
        "\n",
        "    return f1"
      ],
      "metadata": {
        "id": "Ec7q5QAXy5hn"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Best Undersampling Ratio on Validation Set"
      ],
      "metadata": {
        "id": "JMSDIHgSy5rX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing different undersampling ratios on validation set...\")\n",
        "\n",
        "undersampling_ratios = [0.5, 1.0]\n",
        "best_ratio = 1.0\n",
        "best_val_f1 = 0\n",
        "\n",
        "for ratio in undersampling_ratios:\n",
        "    # Apply undersampling with current ratio\n",
        "    rus = RandomUnderSampler(sampling_strategy=ratio, random_state=42)\n",
        "    X_train_under, Y_train_under = rus.fit_resample(X_train, Y_train)\n",
        "\n",
        "    # Train a quick Random Forest model\n",
        "    rf_temp = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    rf_temp.fit(X_train_under, Y_train_under)\n",
        "\n",
        "    # Predict on validation set\n",
        "    Y_val_proba = rf_temp.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    # Optimize threshold on validation set\n",
        "    threshold, val_f1 = optimize_threshold(Y_val, Y_val_proba)\n",
        "\n",
        "    print(f\"Ratio {ratio:.1f} - Validation F1: {val_f1:.4f} (Threshold: {threshold:.3f})\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        best_ratio = ratio\n",
        "\n",
        "print(f\"\\nBest undersampling ratio: {best_ratio} with validation F1: {best_val_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0ruhUNKy5rX",
        "outputId": "0147d903-5c3d-40a1-9f2f-8ffb0e578ea0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing different undersampling ratios on validation set...\n",
            "Ratio 0.5 - Validation F1: 0.7778 (Threshold: 0.890)\n",
            "Ratio 1.0 - Validation F1: 0.7134 (Threshold: 0.890)\n",
            "\n",
            "Best undersampling ratio: 0.5 with validation F1: 0.7778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply Random Undersampling with Best Ratio"
      ],
      "metadata": {
        "id": "G41LlKIIy5xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rus = RandomUnderSampler(sampling_strategy=best_ratio, random_state=42)\n",
        "X_train_under, Y_train_under = rus.fit_resample(X_train, Y_train)\n",
        "\n",
        "print(f\"Original training set size: {len(X_train)}\")\n",
        "print(f\"Undersampled training set size: {len(X_train_under)}\")\n",
        "print(f\"Undersampled - Fraud cases: {Y_train_under.sum()}, Legitimate cases: {(Y_train_under==0).sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRFrIuxty5xo",
        "outputId": "607fb17b-faa6-469a-83df-3d4d94743206"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training set size: 199364\n",
            "Undersampled training set size: 1032\n",
            "Undersampled - Fraud cases: 344, Legitimate cases: 688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply SMOTE Oversampling"
      ],
      "metadata": {
        "id": "pESenMGyy515"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_smote, Y_train_smote = smote.fit_resample(X_train, Y_train)\n",
        "\n",
        "print(f\"Original training set size: {len(X_train)}\")\n",
        "print(f\"SMOTE training set size: {len(X_train_smote)}\")\n",
        "print(f\"SMOTE - Fraud cases: {Y_train_smote.sum()}, Legitimate cases: {(Y_train_smote==0).sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLrYIGi3y515",
        "outputId": "ca2d3b41-9634-4ad6-d73e-9be583bb0c97"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training set size: 199364\n",
            "SMOTE training set size: 398040\n",
            "SMOTE - Fraud cases: 199020, Legitimate cases: 199020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Logistic Regression with Undersampling"
      ],
      "metadata": {
        "id": "FjhqsN5Qy55w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining Logistic Regression with Undersampling...\")\n",
        "lr_under = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_under.fit(X_train_under, Y_train_under)\n",
        "\n",
        "# Optimize threshold on validation set\n",
        "Y_val_proba_lr_under = lr_under.predict_proba(X_val)[:, 1]\n",
        "threshold_lr_under, _ = optimize_threshold(Y_val, Y_val_proba_lr_under)\n",
        "\n",
        "print(f\"Optimal threshold found on validation set: {threshold_lr_under:.3f}\")\n",
        "\n",
        "# Evaluate on test set with optimized threshold\n",
        "f1_lr_under = evaluate_model(lr_under, X_test, Y_test, threshold_lr_under,\n",
        "                              \"Logistic Regression + Undersampling (Test Set)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfpzmYbay55w",
        "outputId": "7bc99352-553c-48f5-b8ba-650d974c70d5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression with Undersampling...\n",
            "Optimal threshold found on validation set: 0.890\n",
            "\n",
            "============================================================\n",
            "Logistic Regression + Undersampling (Test Set)\n",
            "============================================================\n",
            "Threshold: 0.890\n",
            "Accuracy: 0.9962\n",
            "Precision: 0.2897\n",
            "Recall: 0.8378\n",
            "F1-Score: 0.4306\n",
            "ROC-AUC: 0.9683\n",
            "\n",
            "Confusion Matrix:\n",
            "TN: 42496, FP: 152\n",
            "FN: 12, TP: 62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Logistic Regression with SMOTE"
      ],
      "metadata": {
        "id": "0lGJh7ORy59J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining Logistic Regression with SMOTE...\")\n",
        "lr_smote = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_smote.fit(X_train_smote, Y_train_smote)\n",
        "\n",
        "# Optimize threshold on validation set\n",
        "y_val_proba_lr_smote = lr_smote.predict_proba(X_val)[:, 1]\n",
        "threshold_lr_smote, _ = optimize_threshold(Y_val, y_val_proba_lr_smote)\n",
        "\n",
        "print(f\"Optimal threshold found on validation set: {threshold_lr_smote:.3f}\")\n",
        "\n",
        "# Evaluate on test set with optimized threshold\n",
        "f1_lr_smote = evaluate_model(lr_smote, X_test, Y_test, threshold_lr_smote,\n",
        "                             \"Logistic Regression + SMOTE (Test Set)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "athpXh3Dy59J",
        "outputId": "a574f701-ec7c-405b-b667-950ebe031ee7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression with SMOTE...\n",
            "Optimal threshold found on validation set: 0.890\n",
            "\n",
            "============================================================\n",
            "Logistic Regression + SMOTE (Test Set)\n",
            "============================================================\n",
            "Threshold: 0.890\n",
            "Accuracy: 0.9968\n",
            "Precision: 0.3333\n",
            "Recall: 0.8378\n",
            "F1-Score: 0.4769\n",
            "ROC-AUC: 0.9625\n",
            "\n",
            "Confusion Matrix:\n",
            "TN: 42524, FP: 124\n",
            "FN: 12, TP: 62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: Random Forest with Undersampling"
      ],
      "metadata": {
        "id": "_ZKR1vYgy6AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining Random Forest with Undersampling...\")\n",
        "rf_under = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_under.fit(X_train_under, Y_train_under)\n",
        "\n",
        "# Optimize threshold on validation set\n",
        "Y_val_proba_rf_under = rf_under.predict_proba(X_val)[:, 1]\n",
        "threshold_rf_under, _ = optimize_threshold(Y_val, Y_val_proba_rf_under)\n",
        "\n",
        "print(f\"Optimal threshold found on validation set: {threshold_rf_under:.3f}\")\n",
        "\n",
        "# Evaluate on test set with optimized threshold\n",
        "f1_rf_under = evaluate_model(rf_under, X_test, Y_test, threshold_rf_under,\n",
        "                             \"Random Forest + Undersampling (Test Set)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C5257Gty6AE",
        "outputId": "3692a77a-648e-4769-aceb-24f5603dc4de"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Random Forest with Undersampling...\n",
            "Optimal threshold found on validation set: 0.890\n",
            "\n",
            "============================================================\n",
            "Random Forest + Undersampling (Test Set)\n",
            "============================================================\n",
            "Threshold: 0.890\n",
            "Accuracy: 0.9994\n",
            "Precision: 0.8871\n",
            "Recall: 0.7432\n",
            "F1-Score: 0.8088\n",
            "ROC-AUC: 0.9724\n",
            "\n",
            "Confusion Matrix:\n",
            "TN: 42641, FP: 7\n",
            "FN: 19, TP: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: Random Forest with SMOTE"
      ],
      "metadata": {
        "id": "VX2BeXlky6CU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining Random Forest with SMOTE...\")\n",
        "rf_smote = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_smote.fit(X_train_smote, Y_train_smote)\n",
        "\n",
        "# Optimize threshold on validation set\n",
        "Y_val_proba_rf_smote = rf_smote.predict_proba(X_val)[:, 1]\n",
        "threshold_rf_smote, _ = optimize_threshold(Y_val, Y_val_proba_rf_smote)\n",
        "\n",
        "print(f\"Optimal threshold found on validation set: {threshold_rf_smote:.3f}\")\n",
        "\n",
        "# Evaluate on test set with optimized threshold\n",
        "f1_rf_smote = evaluate_model(rf_smote, X_test, Y_test, threshold_rf_smote,\n",
        "                             \"Random Forest + SMOTE (Test Set)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUhbxglwy6CV",
        "outputId": "6a93898c-1074-422a-fa6b-c19764c9e3bb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Random Forest with SMOTE...\n",
            "Optimal threshold found on validation set: 0.670\n",
            "\n",
            "============================================================\n",
            "Random Forest + SMOTE (Test Set)\n",
            "============================================================\n",
            "Threshold: 0.670\n",
            "Accuracy: 0.9996\n",
            "Precision: 0.9516\n",
            "Recall: 0.7973\n",
            "F1-Score: 0.8676\n",
            "ROC-AUC: 0.9455\n",
            "\n",
            "Confusion Matrix:\n",
            "TN: 42645, FP: 3\n",
            "FN: 15, TP: 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Comparison and Best Model Selection"
      ],
      "metadata": {
        "id": "-Yf9_kKpy6FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL MODEL COMPARISON (Test Set F1-Scores)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = {\n",
        "    \"Logistic Regression + Undersampling\": f1_lr_under,\n",
        "    \"Logistic Regression + SMOTE\": f1_lr_smote,\n",
        "    \"Random Forest + Undersampling\": f1_rf_under,\n",
        "    \"Random Forest + SMOTE\": f1_rf_smote\n",
        "}\n",
        "\n",
        "for model_name, f1 in results.items():\n",
        "    print(f\"{model_name}: {f1:.4f}\")\n",
        "\n",
        "best_model_name = max(results, key=results.get)\n",
        "best_f1 = results[best_model_name]\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"BEST MODEL: {best_model_name}\")\n",
        "print(f\"Best F1-Score: {best_f1:.4f}\")\n",
        "print(f\"{'='*60}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uthb9OZ2y6FX",
        "outputId": "39ffe382-5236-42d1-b4e9-629f46b8ce51"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL MODEL COMPARISON (Test Set F1-Scores)\n",
            "============================================================\n",
            "Logistic Regression + Undersampling: 0.4306\n",
            "Logistic Regression + SMOTE: 0.4769\n",
            "Random Forest + Undersampling: 0.8088\n",
            "Random Forest + SMOTE: 0.8676\n",
            "\n",
            "============================================================\n",
            "BEST MODEL: Random Forest + SMOTE\n",
            "Best F1-Score: 0.8676\n",
            "============================================================\n",
            "\n",
            "âœ“ Target F1-Score (>0.85) ACHIEVED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance Analysis (Random Forest Models)"
      ],
      "metadata": {
        "id": "5m-oou11y6IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get feature importance from best Random Forest model\n",
        "if \"Random Forest + Undersampling\" == best_model_name:\n",
        "    feature_importances = rf_under.feature_importances_\n",
        "elif \"Random Forest + SMOTE\" == best_model_name:\n",
        "    feature_importances = rf_smote.feature_importances_\n",
        "else:\n",
        "    # Default to RF with undersampling if best model is LR\n",
        "    feature_importances = rf_under.feature_importances_\n",
        "\n",
        "# Create feature importance dataframe\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance_df.head(10).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtm_vC7Zy6IH",
        "outputId": "54fdb7c7-d800-43cf-b058-d8d332327de8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FEATURE IMPORTANCE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "Feature  Importance\n",
            "    V14    0.209241\n",
            "    V10    0.128348\n",
            "     V4    0.121234\n",
            "    V12    0.098778\n",
            "    V17    0.088056\n",
            "     V3    0.077706\n",
            "    V11    0.049551\n",
            "    V16    0.044210\n",
            "     V2    0.038249\n",
            "     V9    0.027830\n"
          ]
        }
      ]
    }
  ]
}